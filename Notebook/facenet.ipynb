{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c12af7a-abe0-46b3-8de6-e667e9d5f611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n",
      "[DB Loaded] 8 persons\n",
      "[+] Enrolled Absar from absar.png\n",
      "[+] Enrolled Mujahid from mujahid.png\n",
      "[+] Enrolled Sikandar from IMG_1640.JPG\n",
      "[+] Enrolled Sikandar from sikandar1.jpg\n",
      "[+] Enrolled Sikandar from sk.jpg\n",
      "[DB Saved] 11 persons\n",
      "[Attendance] Mujahid at 15:12:34\n",
      "[Attendance] Absar at 15:12:54\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DB_FILE = \"faces_db.npz\"\n",
    "MATCH_THRESHOLD = 0.45  # cosine similarity threshold\n",
    "FRAME_SKIP = 2  # process every N-th frame\n",
    "print(\"[INFO] Using device:\", DEVICE)\n",
    "\n",
    "# ---------------- MODELS ----------------\n",
    "mtcnn = MTCNN(image_size=160, margin=20, keep_all=False, device=DEVICE)\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(DEVICE)\n",
    "\n",
    "# ---------------- DATABASE FUNCTIONS ----------------\n",
    "def load_db(db_path=DB_FILE):\n",
    "    if os.path.exists(db_path):\n",
    "        d = np.load(db_path, allow_pickle=True)\n",
    "        names = d['names'].tolist()\n",
    "        embeddings = d['embeddings']\n",
    "        print(f\"[DB Loaded] {len(names)} persons\")\n",
    "        return names, embeddings\n",
    "    print(\"[DB Loaded] Empty database\")\n",
    "    return [], np.zeros((0, 512), dtype=np.float32)\n",
    "\n",
    "def save_db(names, embeddings, db_path=DB_FILE):\n",
    "    np.savez_compressed(db_path, names=np.array(names), embeddings=np.array(embeddings))\n",
    "    print(f\"[DB Saved] {len(names)} persons\")\n",
    "\n",
    "def normalize_embedding(emb):\n",
    "    return emb / np.linalg.norm(emb)\n",
    "\n",
    "# ---------------- ENROLLMENT ----------------\n",
    "def enroll_from_folder(person_name, folder_path, names, embeddings):\n",
    "    img_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if not img_files:\n",
    "        print(f\"[!] No images found for {person_name}\")\n",
    "        return names, embeddings\n",
    "\n",
    "    person_embs = []\n",
    "    for img_file in img_files:\n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        face = mtcnn(img)\n",
    "        if face is None:\n",
    "            print(f\"[!] No face in {img_file}\")\n",
    "            continue\n",
    "        emb = resnet(face.unsqueeze(0).to(DEVICE)).detach().cpu().numpy()[0]\n",
    "        emb = normalize_embedding(emb)\n",
    "        person_embs.append(emb)\n",
    "        print(f\"[+] Enrolled {person_name} from {img_file}\")\n",
    "\n",
    "    if person_embs:\n",
    "        avg_emb = np.mean(person_embs, axis=0)\n",
    "        avg_emb = normalize_embedding(avg_emb)\n",
    "        names.append(person_name)\n",
    "        embeddings = np.vstack([embeddings, avg_emb])\n",
    "    return names, embeddings\n",
    "\n",
    "# ---------------- MATCHING ----------------\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def recognize_face(face_img, names, embeddings):\n",
    "    face = mtcnn(face_img)\n",
    "    if face is None:\n",
    "        return \"Unknown\", None\n",
    "    emb = resnet(face.unsqueeze(0).to(DEVICE)).detach().cpu().numpy()[0]\n",
    "    emb = normalize_embedding(emb)\n",
    "    sims = [cosine_similarity(emb, e) for e in embeddings]\n",
    "    if not sims:\n",
    "        return \"Unknown\", None\n",
    "    best_idx = int(np.argmax(sims))\n",
    "    if sims[best_idx] >= MATCH_THRESHOLD:\n",
    "        return names[best_idx], sims[best_idx]\n",
    "    else:\n",
    "        return \"Unknown\", sims[best_idx]\n",
    "\n",
    "# ---------------- ATTENDANCE ----------------\n",
    "def mark_attendance(name, log_file=\"attendance.csv\"):\n",
    "    now = datetime.now()\n",
    "    date_str = now.strftime(\"%Y-%m-%d\")\n",
    "    time_str = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    if not os.path.exists(log_file):\n",
    "        with open(log_file, \"w\") as f:\n",
    "            f.write(\"date,name,time\\n\")\n",
    "\n",
    "    with open(log_file, \"r\") as f:\n",
    "        if f\"{date_str},{name}\" in f.read():\n",
    "            return  # already marked today\n",
    "\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"{date_str},{name},{time_str}\\n\")\n",
    "    print(f\"[Attendance] {name} at {time_str}\")\n",
    "\n",
    "# ---------------- REAL-TIME RECOGNITION ----------------\n",
    "def realtime_recognition(names, embeddings, cam_id=0):\n",
    "    cap = cv2.VideoCapture(cam_id)\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % FRAME_SKIP != 0:\n",
    "            cv2.imshow(\"Face Attendance\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            continue\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(rgb_frame)\n",
    "\n",
    "        name, sim = recognize_face(pil_img, names, embeddings)\n",
    "\n",
    "        if name != \"Unknown\":\n",
    "            mark_attendance(name)\n",
    "            label = f\"{name} ({sim:.2f})\"\n",
    "            color = (0, 255, 0)\n",
    "        else:\n",
    "            label = \"Unknown\"\n",
    "            color = (0, 0, 255)\n",
    "\n",
    "        cv2.putText(frame, label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "        cv2.imshow(\"Face Attendance\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Load DB\n",
    "    names, embeddings = load_db()\n",
    "\n",
    "    # Step 2: Enroll new people (folders: dataset/PersonName)\n",
    "    names, embeddings = enroll_from_folder(\"Absar\", \"dataset/Absar\", names, embeddings)\n",
    "    names, embeddings = enroll_from_folder(\"Mujahid\", \"dataset/Mujahid\", names, embeddings)\n",
    "    names, embeddings = enroll_from_folder(\"Sikandar\", \"dataset/Sikandar\", names, embeddings)\n",
    "\n",
    "    # Step 3: Save DB\n",
    "    save_db(names, embeddings)\n",
    "\n",
    "    # Step 4: Real-time recognition\n",
    "    realtime_recognition(names, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4cef700-58df-4386-9a25-62ffb0137a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DB_FILE = \"faces_db.npz\"\n",
    "ATT_FILE = \"attendance.xlsx\"\n",
    "MATCH_THRESHOLD = 0.70  # cosine similarity threshold\n",
    "FRAME_SKIP = 2  # process every N-th frame\n",
    "print(\"[INFO] Using device:\", DEVICE)\n",
    "\n",
    "# ---------------- MODELS ----------------\n",
    "mtcnn = MTCNN(image_size=160, margin=20, keep_all=True, device=DEVICE)  # keep_all=True for multiple faces\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(DEVICE)\n",
    "\n",
    "# ---------------- DATABASE FUNCTIONS ----------------\n",
    "def load_db(db_path=DB_FILE):\n",
    "    if os.path.exists(db_path):\n",
    "        d = np.load(db_path, allow_pickle=True)\n",
    "        names = d['names'].tolist()\n",
    "        embeddings = d['embeddings']\n",
    "        print(f\"[DB Loaded] {len(names)} persons\")\n",
    "        return names, embeddings\n",
    "    print(\"[DB Loaded] Empty database\")\n",
    "    return [], np.zeros((0, 512), dtype=np.float32)\n",
    "\n",
    "def save_db(names, embeddings, db_path=DB_FILE):\n",
    "    np.savez_compressed(db_path, names=np.array(names), embeddings=np.array(embeddings))\n",
    "    print(f\"[DB Saved] {len(names)} persons\")\n",
    "\n",
    "def normalize_embedding(emb):\n",
    "    return emb / np.linalg.norm(emb)\n",
    "\n",
    "# ---------------- ENROLLMENT ----------------\n",
    "def enroll_from_folder(person_name, folder_path, names, embeddings):\n",
    "    img_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if not img_files:\n",
    "        print(f\"[!] No images found for {person_name}\")\n",
    "        return names, embeddings\n",
    "\n",
    "    person_embs = []\n",
    "    for img_file in img_files:\n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        face = mtcnn(img)\n",
    "        if face is None or (isinstance(face, list) and len(face) == 0):\n",
    "            print(f\"[!] No face in {img_file}\")\n",
    "            continue\n",
    "        if isinstance(face, list):  # multiple faces returned\n",
    "            face = face[0]\n",
    "\n",
    "        if face.ndim == 3:\n",
    "            face = face.unsqueeze(0)\n",
    "\n",
    "        emb = resnet(face.to(DEVICE)).detach().cpu().numpy()[0]\n",
    "        emb = normalize_embedding(emb)\n",
    "        person_embs.append(emb)\n",
    "        print(f\"[+] Enrolled {person_name} from {img_file}\")\n",
    "\n",
    "    if person_embs:\n",
    "        avg_emb = np.mean(person_embs, axis=0)\n",
    "        avg_emb = normalize_embedding(avg_emb)\n",
    "        names.append(person_name)\n",
    "        embeddings = np.vstack([embeddings, avg_emb])\n",
    "    return names, embeddings\n",
    "\n",
    "# ---------------- MATCHING ----------------\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def recognize_faces(face_tensors, names, embeddings):\n",
    "    recognized = []\n",
    "    if embeddings.shape[0] == 0:\n",
    "        return [(\"Unknown\", None)] * len(face_tensors)\n",
    "\n",
    "    for face_tensor in face_tensors:\n",
    "        if face_tensor is None:\n",
    "            recognized.append((\"Unknown\", None))\n",
    "            continue\n",
    "\n",
    "        if face_tensor.ndim == 3:\n",
    "            face_tensor = face_tensor.unsqueeze(0)\n",
    "\n",
    "        emb = resnet(face_tensor.to(DEVICE)).detach().cpu().numpy()[0]\n",
    "        emb = normalize_embedding(emb)\n",
    "\n",
    "        sims = [cosine_similarity(emb, e) for e in embeddings]\n",
    "        best_idx = int(np.argmax(sims))\n",
    "        if sims[best_idx] >= MATCH_THRESHOLD:\n",
    "            recognized.append((names[best_idx], sims[best_idx]))\n",
    "        else:\n",
    "            recognized.append((\"Unknown\", sims[best_idx]))\n",
    "    return recognized\n",
    "\n",
    "# ---------------- ATTENDANCE ----------------\n",
    "def init_attendance(names, att_file=ATT_FILE):\n",
    "    today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    if os.path.exists(att_file):\n",
    "        df = pd.read_excel(att_file, index_col=0)\n",
    "    else:\n",
    "        df = pd.DataFrame(index=names)\n",
    "\n",
    "    if today not in df.columns:\n",
    "        df[today] = \"A\"\n",
    "    df.to_excel(att_file)\n",
    "    return df\n",
    "\n",
    "def mark_attendance(name, att_file=ATT_FILE):\n",
    "    today = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    df = pd.read_excel(att_file, index_col=0)\n",
    "\n",
    "    # Ensure today's column exists\n",
    "    if today not in df.columns:\n",
    "        df[today] = \"A\"   # default Absent for all students\n",
    "\n",
    "    # Mark attendance only if not already marked\n",
    "    if name in df.index:\n",
    "        current_status = str(df.at[name, today])  # force single cell string\n",
    "        if current_status != \"P\":\n",
    "            df.at[name, today] = \"P\"\n",
    "            df.to_excel(att_file)\n",
    "            print(f\"[Attendance] {name} marked Present\")\n",
    "        else:\n",
    "            print(f\"[Attendance] {name} already marked Present\")\n",
    "\n",
    "\n",
    "# ---------------- REAL-TIME RECOGNITION ----------------\n",
    "def realtime_recognition(names, embeddings, cam_id=0):\n",
    "    cap = cv2.VideoCapture(cam_id)\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % FRAME_SKIP != 0:\n",
    "            cv2.imshow(\"Face Attendance\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            continue\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(rgb_frame)\n",
    "\n",
    "        # Detect faces + boxes\n",
    "        boxes, probs = mtcnn.detect(pil_img)\n",
    "        faces = mtcnn(pil_img)\n",
    "\n",
    "        if boxes is not None and faces is not None:\n",
    "            if isinstance(faces, torch.Tensor) and faces.ndim == 3:\n",
    "                faces = faces.unsqueeze(0)\n",
    "\n",
    "            results = recognize_faces(faces, names, embeddings)\n",
    "\n",
    "            for box, (name, sim) in zip(boxes, results):\n",
    "                x1, y1, x2, y2 = [int(b) for b in box]\n",
    "                if name != \"Unknown\":\n",
    "                    mark_attendance(name)\n",
    "                    label = f\"{name} ({sim:.2f})\"\n",
    "                    color = (0, 255, 0)\n",
    "                else:\n",
    "                    label = \"Unknown\"\n",
    "                    color = (0, 0, 255)\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        cv2.imshow(\"Face Attendance\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c7ae2f9-eb92-4722-95ba-e436141d9ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB Loaded] 3 persons\n",
      "[Attendance] Sikandar marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n",
      "[Attendance] Sikandar already marked Present\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Load DB\n",
    "    names, embeddings = load_db()\n",
    "\n",
    "    # # Step 2: Enroll new people (folders: dataset/PersonName)\n",
    "    # names, embeddings = enroll_from_folder(\"Absar\", \"dataset/Absar\", names, embeddings)\n",
    "    # names, embeddings = enroll_from_folder(\"Mujahid\", \"dataset/Mujahid\", names, embeddings)\n",
    "    # names, embeddings = enroll_from_folder(\"Sikandar\", \"dataset/Sikandar\", names, embeddings)\n",
    "\n",
    "    # # Step 3: Save DB\n",
    "    # save_db(names, embeddings)\n",
    "\n",
    "    # Step 4: Init attendance Excel\n",
    "    init_attendance(names)\n",
    "\n",
    "    # Step 5: Real-time recognition\n",
    "    realtime_recognition(names, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53fd04f-6f90-433c-99ba-b29fcc3944a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:face_ai]",
   "language": "python",
   "name": "conda-env-face_ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
